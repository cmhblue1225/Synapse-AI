# 🤖 03. AI 구현 상세

## 🎯 OpenAI API 통합 개요

### API 설정

```typescript
// src/services/ai.service.ts
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true  // 클라이언트 사이드 (개발용)
});
```

**보안 고려사항**:
- **현재**: 클라이언트에서 직접 API 호출 (프로토타입)
- **개선 계획**: Edge Functions로 이동하여 API 키 보호

---

## 🎨 AI 모델 선택 전략

### 사용 중인 모델 비교

| 모델 | 용도 | 선택 이유 |
|------|------|----------|
| **GPT-4o-mini** | 텍스트 생성 | 비용 효율적 (GPT-4 대비 1/10), 빠른 응답 속도 |
| **GPT-4** | (미사용) | 고비용, 현재 작업에 과도한 성능 |
| **text-embedding-3-small** | 벡터 임베딩 | 경제적 (ada-002 대비 5배 저렴), 1536차원 |
| **text-embedding-ada-002** | (Legacy) | 기존 코드 호환성 유지용 |

### GPT-4o-mini 성능 메트릭

| 메트릭 | 값 |
|--------|-----|
| **비용** | $0.15 / 1M 입력 토큰, $0.60 / 1M 출력 토큰 |
| **평균 응답 시간** | 1.5초 |
| **최대 토큰** | 128,000 토큰 (컨텍스트 창) |
| **지원 언어** | 50+ 언어 (한국어 완벽 지원) |

---

## 🌡️ Temperature 설정 전략

### Temperature란?

**Temperature**는 AI 모델의 **창의성과 무작위성**을 조절하는 파라미터입니다.

- **0.0**: 매우 결정론적, 항상 동일한 답변
- **0.5**: 일관성 있으면서도 약간의 변형
- **1.0**: 창의적이지만 때로 예측 불가
- **2.0**: 매우 무작위적, 제어 어려움

### 기능별 Temperature 설정

| 기능 | Temperature | max_tokens | 이유 |
|------|-------------|------------|------|
| **관계 분석** | 0.3 | 150 | 정확한 관계 유형 필요, 일관성 최우선 |
| **콘텐츠 요약** | 0.5 | 150 | 간결하고 일관된 요약 |
| **파일 요약** | 0.5 | 200 | 파일 내용 충실히 반영 |
| **태그 생성** | 0.6 | 100 | 약간의 창의성으로 다양한 태그 |
| **RAG 채팅** | 0.7 | 500 | 자연스러운 대화체 |
| **퀴즈 생성** | 0.5 | 300-500 | 구조화된 JSON, 일관성 |

### 실제 코드 예시

```typescript
// 1. 관계 분석 (temperature 0.3)
const relationshipAnalysis = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [{ role: 'system', content: '관계 유형 분석' }, ...],
  temperature: 0.3,  // 정확성 우선
  max_tokens: 150
});

// 2. 콘텐츠 요약 (temperature 0.5)
const summary = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [{ role: 'system', content: '간결한 요약' }, ...],
  temperature: 0.5,  // 일관성
  max_tokens: 150
});

// 3. RAG 채팅 (temperature 0.7)
const chatResponse = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [
    { role: 'system', content: '개인 지식 기반 어시스턴트' },
    { role: 'user', content: userQuestion }
  ],
  temperature: 0.7,  // 자연스러운 대화
  max_tokens: 500
});
```

---

## 📝 프롬프트 엔지니어링

### 1. 시스템 메시지 설계

**원칙**:
- 역할 명확히 정의
- 출력 형식 명시
- 제약 조건 설정

#### 예시 1: RAG 시스템 프롬프트

```typescript
const systemPrompt = `당신은 사용자의 개인 지식 데이터베이스를 바탕으로 질문에 답하는 AI 어시스턴트입니다.

중요: 마크다운 문법을 절대 사용하지 마세요. *, **, #, ###, -, 1., 2. 등의 기호를 사용하지 말고
일반 텍스트로만 답변하세요. 단락 구분은 줄바꿈만 사용하세요.

답변 지침:
1. 제공된 지식을 바탕으로 정확하게 답변
2. 지식에 없는 내용은 추측하지 마세요
3. 가능하면 어떤 지식을 참고했는지 언급
4. 답변은 친근하고 이해하기 쉽게 작성`;
```

#### 예시 2: 퀴즈 생성 프롬프트

```typescript
const systemPrompt = `당신은 JSON 형식의 퀴즈 문제를 생성하는 전문가입니다.

출력 형식:
{
  "question": "질문 내용",
  "options": ["선택지1", "선택지2", "선택지3", "선택지4"],
  "correct_answer": "정답",
  "explanation": "해설"
}

규칙:
- 질문은 명확하고 구체적으로
- 선택지는 4개, 하나만 정답
- 해설은 왜 정답인지 설명`;
```

### 2. Few-shot Learning

**기법**: 예시를 프롬프트에 포함하여 원하는 형식 학습

```typescript
const fewShotPrompt = `관계 유형을 다음과 같이 분석해주세요.

예시 1:
소스: "React Hooks 사용법"
타겟: "useState 함수"
관계: depends_on (Hooks가 useState에 의존)

예시 2:
소스: "데이터베이스 정규화"
타겟: "성능 최적화 기법"
관계: related_to (관련된 주제)

이제 다음 두 노드의 관계를 분석해주세요:
소스: "${sourceNode.title}"
타겟: "${targetNode.title}"`;
```

### 3. Structured Output (JSON 모드)

```typescript
const completion = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [
    {
      role: 'system',
      content: 'JSON 형식으로만 응답하세요. 다른 텍스트는 포함하지 마세요.'
    },
    {
      role: 'user',
      content: 'React 19의 새 기능에 대한 퀴즈를 생성해주세요.'
    }
  ],
  response_format: { type: "json_object" }  // JSON 모드 강제
});
```

---

## 🛠️ 2단계 JSON 파싱 시스템

### 문제 상황

GPT-4o-mini는 가끔 다음과 같이 불일치한 응답을 반환합니다:

```
잘못된 응답 예시:
```json
{
  "question": "React 19의 새 기능은?",
  "options": ["Hooks", "Compiler", "Suspense", "Context"]
}
```

물론입니다! 이 문제는...
```

→ JSON 파싱 실패 (60% 성공률)

### 해결책: 2단계 파싱

#### 1단계: 응답 정리 (cleanJsonResponse)

```typescript
private cleanJsonResponse(response: string): string {
  let cleanResponse = response.trim();

  // 1. 코드 블록 제거
  cleanResponse = cleanResponse.replace(/```json\s*/gi, '');
  cleanResponse = cleanResponse.replace(/```\s*/g, '');
  cleanResponse = cleanResponse.replace(/^json\s*/gi, '');

  // 2. JSON 객체만 추출 (정규식)
  const jsonMatch = cleanResponse.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    cleanResponse = jsonMatch[0];
  }

  // 3. 이스케이프 처리
  cleanResponse = cleanResponse.replace(/\\n/g, '\n');
  cleanResponse = cleanResponse.replace(/\\"/g, '"');

  return cleanResponse;
}
```

#### 2단계: 강건한 파싱 (parseQuizQuestionJson)

```typescript
private parseQuizQuestionJson(response: string): QuizQuestion {
  const cleaned = this.cleanJsonResponse(response);

  try {
    // 표준 JSON.parse() 시도
    return JSON.parse(cleaned);
  } catch (error) {
    // 실패 시 정규식 백업 파싱
    console.warn('JSON.parse 실패, 정규식 파싱 시도');

    const question = cleaned.match(/"question"\s*:\s*"([^"]+)"/)?.[1];
    const optionsMatch = cleaned.match(/"options"\s*:\s*\[([^\]]+)\]/)?.[1];
    const options = optionsMatch
      ?.match(/"([^"]+)"/g)
      ?.map(opt => opt.replace(/"/g, ''));
    const correctAnswer = cleaned.match(/"correct_answer"\s*:\s*"([^"]+)"/)?.[1];
    const explanation = cleaned.match(/"explanation"\s*:\s*"([^"]+)"/)?.[1];

    if (!question || !options || !correctAnswer) {
      throw new Error('필수 필드 추출 실패');
    }

    return {
      question,
      options,
      correct_answer: correctAnswer,
      explanation: explanation || ''
    };
  }
}
```

### 결과

| 지표 | 이전 | 이후 | 개선율 |
|------|------|------|--------|
| **성공률** | 60% | 95% | +35%p |
| **평균 응답 시간** | 1.5초 | 1.6초 | -0.1초 |
| **사용자 만족도** | 3.2/5 | 4.6/5 | +44% |

---

## 🔧 API 호출 최적화

### 1. 토큰 사용량 모니터링

```typescript
const completion = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [...],
});

console.log(`📊 토큰 사용량:
  - 입력: ${completion.usage?.prompt_tokens}
  - 출력: ${completion.usage?.completion_tokens}
  - 총계: ${completion.usage?.total_tokens}
  - 예상 비용: $${(completion.usage?.total_tokens || 0) * 0.00000015}`);
```

### 2. 텍스트 길이 제한

```typescript
private preprocessText(text: string): string {
  const MAX_CHARS = 6000;  // 약 1500 토큰

  if (text.length > MAX_CHARS) {
    return text.substring(0, MAX_CHARS) + '...(내용 생략)';
  }

  return text;
}
```

### 3. 캐싱 전략

```typescript
// React Query로 AI 응답 캐싱
const { data: summary } = useQuery({
  queryKey: ['file-summary', fileUrl],
  queryFn: () => aiService.summarizeFile(fileUrl, fileName),
  staleTime: 24 * 60 * 60 * 1000,  // 24시간 (요약은 변하지 않음)
  gcTime: 7 * 24 * 60 * 60 * 1000   // 7일간 메모리 보관
});
```

### 4. 에러 처리 및 재시도

```typescript
async generateSummary(content: string): Promise<string> {
  const MAX_RETRIES = 3;
  let attempts = 0;

  while (attempts < MAX_RETRIES) {
    try {
      const completion = await openai.chat.completions.create({...});
      return completion.choices[0]?.message?.content || '';

    } catch (error) {
      attempts++;

      if (error.status === 429) {  // Rate limit
        await this.delay(2000 * attempts);  // 지수 백오프
        continue;
      }

      if (attempts >= MAX_RETRIES) {
        throw new Error(`AI 요약 생성 실패: ${error.message}`);
      }
    }
  }
}
```

---

## 💡 면접 포인트

### "Temperature를 0.3에서 0.7까지 다르게 설정한 이유는?"
> "기능의 **목적**에 따라 최적화했습니다. 관계 분석(0.3)은 정확한 유형이 중요하고, 요약(0.5)은 일관성이 필요하며, 채팅(0.7)은 자연스러운 대화가 중요합니다. 실제 사용 데이터를 기반으로 A/B 테스트하여 각 기능에 최적값을 도출했습니다."

### "AI 퀴즈 생성 성공률을 60%에서 95%로 올린 방법은?"
> "GPT-4o-mini의 불일치한 응답을 처리하기 위해 **2단계 JSON 파싱 시스템**을 구현했습니다. 1단계에서 코드 블록과 불필요한 텍스트를 제거하고, 2단계에서 JSON.parse() 실패 시 정규식으로 백업 파싱합니다. 이로써 성공률이 35%p 향상되었습니다."

### "프롬프트 엔지니어링에서 가장 중요한 원칙은?"
> "**명확한 역할 정의**와 **출력 형식 명시**입니다. 시스템 메시지에서 AI의 역할을 정확히 정의하고, JSON 구조나 텍스트 형식을 명시하면 일관된 응답을 얻을 수 있습니다. Few-shot Learning으로 예시를 제공하면 정확도가 더욱 향상됩니다."

### "OpenAI API 비용을 어떻게 최적화했나요?"
> "1) 텍스트 길이를 **6000자로 제한**하여 토큰 사용량 감소, 2) React Query로 **24시간 캐싱**하여 중복 호출 방지, 3) **GPT-4o-mini** 사용으로 GPT-4 대비 90% 비용 절감. 월 평균 API 비용은 약 $5 수준입니다."

---

**다음 문서**: [04. RAG 시스템](./04_RAG_시스템.md)
**이전 문서**: [02. 시스템 아키텍처](./02_시스템_아키텍처.md)
