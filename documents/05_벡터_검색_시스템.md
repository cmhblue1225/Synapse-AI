# ğŸ” 05. ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ

## ğŸ¯ ë²¡í„° ê²€ìƒ‰ì˜ í•µì‹¬ ê°œë…

### ì „í†µì  í‚¤ì›Œë“œ ê²€ìƒ‰ vs ë²¡í„° ê²€ìƒ‰

| ë¹„êµ í•­ëª© | í‚¤ì›Œë“œ ê²€ìƒ‰ | ë²¡í„° ê²€ìƒ‰ |
|-----------|-------------|-----------|
| **ê²€ìƒ‰ ë°©ì‹** | ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ | ì˜ë¯¸ ìœ ì‚¬ë„ |
| **ì˜ˆì‹œ ì¿¼ë¦¬** | "React Hooks" | "ë¦¬ì•¡íŠ¸ í•¨ìˆ˜í˜• ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê´€ë¦¬" |
| **ê²€ìƒ‰ ê²°ê³¼** | "React Hooks" í¬í•¨ ë¬¸ì„œë§Œ | Hooks ê´€ë ¨ ëª¨ë“  ë¬¸ì„œ (ë‹¨ì–´ ì—†ì–´ë„) |
| **ì •í™•ë„** | ë†’ìŒ (ì •í™• ë§¤ì¹­) | ì¤‘ê°„ (ì˜ë¯¸ ê¸°ë°˜) |
| **ì¬í˜„ìœ¨** | ë‚®ìŒ (ë™ì˜ì–´ ëˆ„ë½) | ë†’ìŒ (ì˜ë¯¸ ìœ ì‚¬ ëª¨ë‘ í¬í•¨) |

### ë²¡í„° ì„ë² ë”©ì´ë€?

**í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜**í•˜ì—¬ ì»´í“¨í„°ê°€ ì˜ë¯¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

```
"React Hooksë¥¼ ì‚¬ìš©í•œ ìƒíƒœ ê´€ë¦¬"
          â†“ OpenAI Embedding
[0.123, -0.456, 0.789, ..., 0.321]  (1536ì°¨ì›)

"ë¦¬ì•¡íŠ¸ í•¨ìˆ˜í˜• ì»´í¬ë„ŒíŠ¸ì˜ state ê´€ë¦¬"
          â†“ OpenAI Embedding
[0.118, -0.442, 0.795, ..., 0.315]  (1536ì°¨ì›)

ì½”ì‚¬ì¸ ìœ ì‚¬ë„: 0.95 â†’ ë§¤ìš° ìœ ì‚¬í•¨!
```

---

## ğŸ¤– ì„ë² ë”© ëª¨ë¸ ì„ íƒ

### OpenAI ì„ë² ë”© ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | ì°¨ì› | ë¹„ìš© | ì„±ëŠ¥ | ì„ íƒ |
|------|------|------|------|------|
| **text-embedding-3-large** | 3072 | $0.13 / 1M í† í° | ìµœê³  | âŒ (ê³¼ë„í•œ ì„±ëŠ¥) |
| **text-embedding-3-small** | 1536 | $0.02 / 1M í† í° | ìš°ìˆ˜ | âœ… **ì±„íƒ** |
| **text-embedding-ada-002** | 1536 | $0.10 / 1M í† í° | ì–‘í˜¸ | âŒ (5ë°° ë¹„ìŒˆ) |

**ì„ íƒ ì´ìœ **:
- text-embedding-3-smallì€ **ada-002 ëŒ€ë¹„ 5ë°° ì €ë ´**
- ì„±ëŠ¥ì€ ì˜¤íˆë ¤ ë” ìš°ìˆ˜ (MTEB ë²¤ì¹˜ë§ˆí¬ 62.3% vs 61.0%)
- 1536ì°¨ì›ìœ¼ë¡œ ì¶©ë¶„í•œ í‘œí˜„ë ¥

---

## ğŸ’¾ pgvector + PostgreSQL

### pgvector í™•ì¥

**pgvector**ëŠ” PostgreSQLì—ì„œ ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” í™•ì¥ì…ë‹ˆë‹¤.

```sql
-- í™•ì¥ ì„¤ì¹˜
CREATE EXTENSION IF NOT EXISTS vector;

-- ë²¡í„° ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE knowledge_nodes
ADD COLUMN embedding VECTOR(1536);

-- ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (IVFFlat)
CREATE INDEX ON knowledge_nodes
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

### IVFFlat vs HNSW ì¸ë±ìŠ¤

| ì¸ë±ìŠ¤ | ì†ë„ | ì •í™•ë„ | ë©”ëª¨ë¦¬ | ì„ íƒ |
|--------|------|--------|--------|------|
| **IVFFlat** | ë¹ ë¦„ | 98% | ë””ìŠ¤í¬ ê¸°ë°˜ | âœ… **ì±„íƒ** |
| **HNSW** | ë§¤ìš° ë¹ ë¦„ | 99% | ë©”ëª¨ë¦¬ ê¸°ë°˜ (ë§ì´ ì‚¬ìš©) | âŒ |

**IVFFlat ì„ íƒ ì´ìœ **:
- ë””ìŠ¤í¬ ê¸°ë°˜ìœ¼ë¡œ **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ìŒ**
- ì¤‘ì†Œ ê·œëª¨ ë°ì´í„°ì…‹(< 100ë§Œ ê°œ)ì— ì¶©ë¶„
- lists = 100 ì„¤ì • (í´ëŸ¬ìŠ¤í„° ìˆ˜)

**lists íŒŒë¼ë¯¸í„°**:
```
rows < 1M: lists = rows / 1000 (ê¶Œì¥)
rows = 10K: lists = 10  (ë„ˆë¬´ ì‘ìŒ)
rows = 100K: lists = 100 âœ… (ìµœì )
rows = 1M: lists = 1000  (í° ë°ì´í„°ì…‹)
```

---

## ğŸ“ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°

### ìˆ˜í•™ì  ê³µì‹

```
ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = (A Â· B) / (||A|| Ã— ||B||)

A Â· B = ë‚´ì  (dot product)
||A|| = ë²¡í„° Aì˜ í¬ê¸° (norm)
||B|| = ë²¡í„° Bì˜ í¬ê¸° (norm)
```

### TypeScript êµ¬í˜„

```typescript
// src/services/embedding.service.ts
private cosineSimilarity(vecA: number[], vecB: number[]): number {
  if (vecA.length !== vecB.length) {
    throw new Error(`ë²¡í„° ì°¨ì›ì´ ë‹¤ë¦…ë‹ˆë‹¤: ${vecA.length} vs ${vecB.length}`);
  }

  let dotProduct = 0;  // A Â· B
  let normA = 0;       // ||A||
  let normB = 0;       // ||B||

  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }

  if (normA === 0 || normB === 0) {
    return 0;  // ì˜ë²¡í„°ëŠ” ìœ ì‚¬ë„ 0
  }

  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
```

### ìœ ì‚¬ë„ ë²”ìœ„

```
ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë²”ìœ„: -1.0 ~ 1.0

1.0   : ì™„ì „íˆ ë™ì¼ (ê°™ì€ ë°©í–¥)
0.9   : ë§¤ìš° ìœ ì‚¬
0.7   : ìœ ì‚¬
0.5   : ì–´ëŠ ì •ë„ ê´€ë ¨
0.3   : ì•½ê°„ ê´€ë ¨
0.0   : ë¬´ê´€í•¨
-1.0  : ì™„ì „íˆ ë°˜ëŒ€ (ë°˜ëŒ€ ë°©í–¥)
```

---

## ğŸ”§ ì„ë² ë”© ìƒì„± íŒŒì´í”„ë¼ì¸

### 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬

```typescript
private preprocessText(text: string): string {
  // 1. HTML íƒœê·¸ ì œê±°
  let cleaned = text.replace(/<[^>]*>/g, ' ');

  // 2. ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
  cleaned = cleaned.replace(/\s+/g, ' ');

  // 3. ì•ë’¤ ê³µë°± ì œê±°
  cleaned = cleaned.trim();

  // 4. ê¸¸ì´ ì œí•œ (OpenAI í† í° í•œë„)
  const MAX_CHARS = 6000;  // ì•½ 1500 í† í°
  if (cleaned.length > MAX_CHARS) {
    cleaned = cleaned.substring(0, MAX_CHARS) + '...';
  }

  return cleaned;
}
```

### 2. ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© (ì œëª© + ë‚´ìš© + íŒŒì¼)

```typescript
// src/services/embedding.service.ts
async generateAndStoreNodeEmbedding(
  nodeId: string,
  title: string,
  content: string,
  files?: File[]
): Promise<void> {
  // 1. íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  let fileText = '';
  if (files && files.length > 0) {
    const { FileTextExtractor } = await import('../lib/fileTextExtractor');
    fileText = await FileTextExtractor.extractTextFromFiles(files);
  }

  // 2. ì œëª©, ë‚´ìš©, íŒŒì¼ì„ êµ¬ë¶„ìë¡œ ê²°í•©
  const combinedText = [
    `ì œëª©: ${title}`,
    content ? `ë‚´ìš©: ${content}` : '',
    fileText ? `ì²¨ë¶€ íŒŒì¼: ${fileText}` : ''
  ]
    .filter(text => text.trim().length > 0)
    .join('\n\n---\n\n');

  // 3. ì „ì²˜ë¦¬
  const processedText = this.preprocessText(combinedText);

  // 4. OpenAI API í˜¸ì¶œ
  const embedding = await this.generateEmbedding(processedText);

  // 5. PostgreSQLì— ì €ì¥ (VECTOR íƒ€ì…)
  await supabase
    .from('knowledge_nodes')
    .update({
      embedding: JSON.stringify(embedding),
      updated_at: new Date().toISOString()
    })
    .eq('id', nodeId);
}
```

### 3. ë°°ì¹˜ ì„ë² ë”©

```typescript
async generateBatchEmbeddings(texts: string[]): Promise<number[][]> {
  const BATCH_SIZE = 100;  // OpenAI ì œí•œ: ìµœëŒ€ 2048ê°œ
  const results: number[][] = [];

  for (let i = 0; i < texts.length; i += BATCH_SIZE) {
    const batch = texts.slice(i, i + BATCH_SIZE);

    // ì „ì²˜ë¦¬
    const cleanBatch = batch.map(text => this.preprocessText(text));

    // OpenAI API ë°°ì¹˜ í˜¸ì¶œ
    const response = await fetch(`${this.OPENAI_API_URL}/embeddings`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'text-embedding-3-small',
        input: cleanBatch,
        encoding_format: 'float'
      }),
    });

    const data = await response.json();
    const batchResults = data.data.map((item: any) => item.embedding);
    results.push(...batchResults);

    // Rate limit íšŒí”¼ (100ms ëŒ€ê¸°)
    if (i + BATCH_SIZE < texts.length) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }
  }

  return results;
}
```

---

## ğŸ” ì‹œë§¨í‹± ê²€ìƒ‰ êµ¬í˜„

### Top-K ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜

```typescript
async semanticSearch(
  query: string,
  options: {
    limit?: number;                // Top-K
    similarity_threshold?: number; // ìµœì†Œ ìœ ì‚¬ë„
    node_types?: string[];         // ë…¸ë“œ íƒ€ì… í•„í„°
    tags?: string[];               // íƒœê·¸ í•„í„°
    user_id?: string;              // ì‚¬ìš©ì í•„í„°
  } = {}
): Promise<SemanticSearchResult[]> {
  const {
    limit = 10,
    similarity_threshold = 0.3,
    node_types,
    tags,
    user_id
  } = options;

  console.log(`ğŸ” ì‹œë§¨í‹± ê²€ìƒ‰: "${query}"`);

  // 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
  const queryEmbedding = await this.generateEmbedding(query);

  // 2. ëª¨ë“  í™œì„± ë…¸ë“œ ì¡°íšŒ
  let queryBuilder = supabase
    .from('knowledge_nodes')
    .select('id, title, content, node_type, tags, created_at, updated_at, embedding')
    .eq('is_active', true)
    .not('embedding', 'is', null);

  // ì‚¬ìš©ì í•„í„°ë§
  if (user_id) {
    queryBuilder = queryBuilder.eq('user_id', user_id);
  }

  const { data: nodes, error } = await queryBuilder;

  if (error || !nodes) {
    throw new Error(`ë…¸ë“œ ì¡°íšŒ ì‹¤íŒ¨: ${error?.message}`);
  }

  console.log(`ğŸ“Š ê²€ìƒ‰ ëŒ€ìƒ: ${nodes.length}ê°œ ë…¸ë“œ`);

  // 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
  const results: SemanticSearchResult[] = [];

  for (const node of nodes) {
    // ì„ë² ë”© íŒŒì‹±
    const nodeEmbedding = typeof node.embedding === 'string'
      ? JSON.parse(node.embedding)
      : node.embedding;

    // ìœ ì‚¬ë„ ê³„ì‚°
    const similarity = this.cosineSimilarity(queryEmbedding, nodeEmbedding);

    // Threshold í•„í„°ë§
    if (similarity < similarity_threshold) {
      continue;
    }

    // ë…¸ë“œ íƒ€ì… í•„í„°ë§
    if (node_types && node_types.length > 0) {
      if (!node_types.includes(node.node_type)) {
        continue;
      }
    }

    // íƒœê·¸ í•„í„°ë§
    if (tags && tags.length > 0) {
      if (!node.tags || !tags.some(tag => node.tags.includes(tag))) {
        continue;
      }
    }

    results.push({
      id: node.id,
      title: node.title,
      content: node.content,
      similarity,
      node_type: node.node_type,
      tags: node.tags,
      created_at: node.created_at,
      updated_at: node.updated_at
    });
  }

  // 4. ìœ ì‚¬ë„ ìˆœ ì •ë ¬ (ë†’ì€ ìˆœ)
  results.sort((a, b) => b.similarity - a.similarity);

  // 5. Top-K ë°˜í™˜
  const topK = results.slice(0, limit);

  console.log(`âœ… ê²€ìƒ‰ ì™„ë£Œ: ${topK.length}ê°œ ê²°ê³¼ (threshold ${similarity_threshold})`);
  topK.forEach((result, index) => {
    console.log(`  ${index + 1}. ${result.title} (${result.similarity.toFixed(3)})`);
  });

  return topK;
}
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ì¸ë±ìŠ¤ ìµœì í™”

```sql
-- IVFFlat ì¸ë±ìŠ¤ë¡œ ê²€ìƒ‰ ì†ë„ 100ë°° í–¥ìƒ
EXPLAIN ANALYZE
SELECT id, title, embedding <=> '[0.1, 0.2, ...]' AS distance
FROM knowledge_nodes
ORDER BY distance
LIMIT 10;

-- ì¸ë±ìŠ¤ ì—†ìŒ: 2500ms (ì „ì²´ ìŠ¤ìº”)
-- IVFFlat ì¸ë±ìŠ¤: 25ms (100ë°° í–¥ìƒ)
```

### 2. ìºì‹± ì „ëµ

```typescript
// ì„ë² ë”© ê²°ê³¼ ìºì‹± (24ì‹œê°„)
const { data: embedding } = useQuery({
  queryKey: ['embedding', nodeId],
  queryFn: () => embeddingService.generateAndStoreNodeEmbedding(...),
  staleTime: 24 * 60 * 60 * 1000,  // ì„ë² ë”©ì€ ë³€í•˜ì§€ ì•ŠìŒ
  gcTime: 7 * 24 * 60 * 60 * 1000   // 7ì¼ê°„ ë³´ê´€
});
```

### 3. í˜ì´ì§€ë„¤ì´ì…˜

```typescript
// Offset ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜
async semanticSearchWithPagination(
  query: string,
  page: number = 1,
  pageSize: number = 10
): Promise<PaginatedResults> {
  const allResults = await this.semanticSearch(query, {
    limit: page * pageSize  // í•„ìš”í•œ ë§Œí¼ë§Œ
  });

  return {
    data: allResults.slice((page - 1) * pageSize, page * pageSize),
    total: allResults.length,
    page,
    pageSize
  };
}
```

---

## ğŸ’¡ ë©´ì ‘ í¬ì¸íŠ¸

### "ë²¡í„° ê²€ìƒ‰ì˜ ì¥ì ì€?"
> "**ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰**ìœ¼ë¡œ í‚¤ì›Œë“œê°€ ì •í™•íˆ ì—†ì–´ë„ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë¦¬ì•¡íŠ¸ í•¨ìˆ˜í˜• ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê´€ë¦¬'ë¡œ ê²€ìƒ‰í•˜ë©´ 'React Hooks' ë¬¸ì„œë„ ì°¾ì„ ìˆ˜ ìˆì£ . ì¬í˜„ìœ¨ì´ ë†’ì•„ ì‚¬ìš©ì ê²½í—˜ì´ ì¢‹ìŠµë‹ˆë‹¤."

### "ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì§ì ‘ êµ¬í˜„í•œ ì´ìœ ëŠ”?"
> "pgvectorê°€ ì„œë²„ ì‚¬ì´ë“œì—ì„œ ê³„ì‚°í•˜ì§€ë§Œ, **í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìºì‹±ëœ ë²¡í„°ë¥¼ ì¬ê²€ìƒ‰**í•  ë•Œë„ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ ë””ë²„ê¹…ê³¼ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì§ì ‘ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤."

### "IVFFlatë¥¼ HNSW ëŒ€ì‹  ì„ íƒí•œ ì´ìœ ëŠ”?"
> "HNSWëŠ” ë” ë¹ ë¥´ì§€ë§Œ **ë©”ëª¨ë¦¬ ê¸°ë°˜**ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. í˜„ì¬ ë°ì´í„°ì…‹ ê·œëª¨(< 10ë§Œ ê°œ)ì—ì„œëŠ” IVFFlatì˜ 98% ì •í™•ë„ì™€ ë””ìŠ¤í¬ ê¸°ë°˜ ì €ì¥ì´ ë” ì í•©í•˜ê³  ë¹„ìš© íš¨ìœ¨ì ì…ë‹ˆë‹¤."

### "ì„ë² ë”© ì°¨ì›ì´ 1536ì¸ ì´ìœ ëŠ”?"
> "OpenAI **text-embedding-3-small** ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì›ì…ë‹ˆë‹¤. 3072ì°¨ì›ì˜ large ëª¨ë¸ ëŒ€ë¹„ **ì„±ëŠ¥ì€ ê±°ì˜ ë™ì¼í•˜ë©´ì„œ ì €ì¥ ê³µê°„ì€ 50% ì ˆì•½**ë©ë‹ˆë‹¤."

---

**ë‹¤ìŒ ë¬¸ì„œ**: [06. PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](./06_PDF_ì²˜ë¦¬_íŒŒì´í”„ë¼ì¸.md)
**ì´ì „ ë¬¸ì„œ**: [04. RAG ì‹œìŠ¤í…œ](./04_RAG_ì‹œìŠ¤í…œ.md)
